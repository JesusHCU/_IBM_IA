{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b777bf27-5a84-4946-942e-ccb9aeeeba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportar e imprmir a un modelo entrenado de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ecea04-36df-40e3-9460-8a2111b2e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en el fichero: modelo_rf.pkl\n",
      "Modelo cargado desde el fichero.\n",
      "Predicciones realizadas con el modelo cargado:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd  # Para manejar datos en formato de DataFrame\n",
    "from sklearn.datasets import load_iris  # Para cargar el dataset Iris\n",
    "from sklearn.model_selection import train_test_split  # Para dividir los datos en entrenamiento y prueba\n",
    "from sklearn.ensemble import RandomForestClassifier  # Para el modelo de clasificación\n",
    "import pickle  # Para guardar y cargar el modelo en formato binario\n",
    "\n",
    "# 1. Cargar el conjunto de datos\n",
    "# Usamos el conjunto de datos Iris como un ejemplo\n",
    "datos = load_iris()  # Cargamos el dataset Iris\n",
    "X = datos.data  # Variables independientes (características)\n",
    "y = datos.target  # Variable dependiente (etiquetas)\n",
    "\n",
    "# 2. Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Entrenar el modelo\n",
    "# Creamos un modelo de Random Forest\n",
    "modelo = RandomForestClassifier(n_estimators=100, random_state=42)  # Inicializamos el modelo\n",
    "modelo.fit(X_train, y_train)  # Entrenamos el modelo con los datos de entrenamiento\n",
    "\n",
    "# 4. Exportar el modelo a un fichero\n",
    "# Guardamos el modelo entrenado en un fichero binario utilizando pickle\n",
    "nombre_fichero = 'modelo_rf.pkl'  # Nombre del fichero donde guardaremos el modelo\n",
    "with open(nombre_fichero, 'wb') as archivo:  # Abrimos el fichero en modo escritura binaria\n",
    "    pickle.dump(modelo, archivo)  # Guardamos el modelo en el fichero\n",
    "print(f\"Modelo guardado en el fichero: {nombre_fichero}\")\n",
    "\n",
    "# 5. Importar el modelo desde un fichero\n",
    "# Cargamos el modelo previamente guardado\n",
    "with open(nombre_fichero, 'rb') as archivo:  # Abrimos el fichero en modo lectura binaria\n",
    "    modelo_cargado = pickle.load(archivo)  # Cargamos el modelo desde el fichero\n",
    "print(\"Modelo cargado desde el fichero.\")\n",
    "\n",
    "# 6. Evaluar el modelo cargado\n",
    "# Realizamos predicciones con el modelo cargado\n",
    "predicciones = modelo_cargado.predict(X_test)  # Usamos el modelo cargado para hacer predicciones\n",
    "\n",
    "# Imprimimos las predicciones\n",
    "print(\"Predicciones realizadas con el modelo cargado:\")\n",
    "print(predicciones)\n",
    "\n",
    "# 7. Opcional: Guardar y recuperar un modelo de un fichero binario pickle\n",
    "# Este proceso se realiza en los pasos 4 y 5, donde guardamos y luego cargamos el modelo\n",
    "# Utilizamos el mismo fichero para demostrar que el modelo se puede persistir y recuperar correctamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f497f-909f-4d33-ae29-82e10f7e36e5",
   "metadata": {},
   "source": [
    "Explicación de cada sección del código:\n",
    "Importaciones:\n",
    "\n",
    "Importamos las bibliotecas necesarias: pandas para manipulación de datos, load_iris para obtener un conjunto de datos, train_test_split para dividir los datos, RandomForestClassifier para crear el modelo de Machine Learning y pickle para guardar y cargar el modelo en formato binario.\n",
    "Cargar el Conjunto de Datos:\n",
    "\n",
    "Utilizamos el conjunto de datos Iris como ejemplo. X contiene las características y y contiene las etiquetas de las clases.\n",
    "Dividir los Datos:\n",
    "\n",
    "Dividimos los datos en conjuntos de entrenamiento y prueba para evaluar el modelo. En este caso, usamos un 80% de los datos para entrenar y un 20% para probar.\n",
    "Entrenar el Modelo:\n",
    "\n",
    "Creamos un modelo de Random Forest y lo entrenamos con los datos de entrenamiento.\n",
    "Exportar el Modelo:\n",
    "\n",
    "Utilizamos pickle para guardar el modelo entrenado en un fichero. El fichero se abre en modo escritura binaria ('wb'), y luego usamos pickle.dump() para escribir el modelo en el fichero.\n",
    "Importar el Modelo:\n",
    "\n",
    "Para cargar el modelo, abrimos el fichero en modo lectura binaria ('rb') y utilizamos pickle.load() para leer el modelo desde el fichero.\n",
    "Evaluar el Modelo Cargado:\n",
    "\n",
    "Una vez cargado el modelo, hacemos predicciones sobre el conjunto de prueba y las imprimimos para verificar que el modelo cargado funciona correctamente.\n",
    "Notas sobre el uso de pickle:\n",
    "pickle es una biblioteca en Python que permite serializar (convertir en un formato que se puede guardar) y deserializar (recuperar el formato original) objetos de Python.\n",
    "Es útil para guardar modelos de Machine Learning entrenados, lo que permite reutilizarlos sin necesidad de volver a entrenar.\n",
    "Es importante tener en cuenta que pickle es específico de Python, por lo que los modelos guardados no pueden ser usados directamente en otros lenguajes de programación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
